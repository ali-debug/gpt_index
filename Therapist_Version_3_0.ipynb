{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ali-debug/gpt_index/blob/main/Therapist_Version_3_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAuM6Rb_9G8s",
        "outputId": "3e9bf40b-3ba1-44bb-b559-11cdab0d2223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.7 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi4t1OQV9Dyy",
        "outputId": "bcf3b220-7ef4-43cf-ba9f-bdef5ab08620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT3.5 Turbo response: \n",
            "Hello! How can I assist you today?\n",
            "GPT3.5 Turbo response: \n",
            "As an AI language model, I don't have feelings, but I'm always here to help you. How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "# Importing Libraries\n",
        "import openai\n",
        "import os\n",
        "\n",
        "#from api_secrets import API_KEY\n",
        "openai.api_key= \"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\"\n",
        "\n",
        "identity = '''\n",
        "Your name is Therapist! You are an expert Psychotherapist/consultant/companion and you empethatically & intelligently answer questions of users related to emotion based texts only.\n",
        "You act only as a therapist/friend/companion and do not answer to any question related to any other field you only says sorry i don't know.\n",
        "In your first conversation with user, you start a conversation with introducing yourself and ask them for their introduction such as name.\n",
        "Your goal is to be a friend and a companion to them who talks to them, listens them, leads conversation and suggests good and valuable ideas that help them.\n",
        "You have the ability to build context and remember converstaions, especially the user name, age, gender, birthday and any information that may help you give a personalized experience to them when they talk to you.\n",
        "Note : - Avoid prefix and postfix in your responses.\n",
        "\n",
        "Let's understand how you will introduce yourself.\n",
        "\n",
        "Example: -\n",
        "1) Hello! My name is Therapist. How are you feeling today?\n",
        "'''\n",
        "# Identity of model for chatbot based on Psychotherapist\n",
        "message = [{\"role\": \"system\", \"content\" : identity}]\n",
        "\n",
        "# Function for model.\n",
        "def chat(user,message):\n",
        "\n",
        "  message.append({\"role\": \"user\", \"content\" :user})\n",
        "\n",
        "# Engine\n",
        "  completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages = message,\n",
        "    temperature=0.1,\n",
        "    max_tokens=500)\n",
        "\n",
        "# Fetching the output.\n",
        "  output = completion['choices'][0]['message']['content']\n",
        "\n",
        "  if output[0] == \"?\":\n",
        "    output = output[1:]\n",
        "\n",
        "# printing model result.\n",
        "  print(\"GPT3.5 Turbo response: \\n\"+output)\n",
        "\n",
        "# Maintainging the context.\n",
        "  message.append({\"role\": \"assistant\", \"content\" : output})\n",
        "\n",
        "# return the output\n",
        "  return output\n",
        "\n",
        "# User Queries list.\n",
        "user_response = []\n",
        "\n",
        "# Model Answers list.\n",
        "bot_response = []\n",
        "\n",
        "\n",
        "# Start of program to test\n",
        "while True:\n",
        "  # Taking input until user enter quit to exit\n",
        "  user = input(\"Input : - \")\n",
        "\n",
        "  if user ==\"quit\":\n",
        "    break\n",
        "\n",
        "# Working of engine.\n",
        "  else:\n",
        "    user_response.append(user)\n",
        "    out = chat(user,message)\n",
        "    bot_response.append(out)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPi7nqZyodrlJcG4ItX87o/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}